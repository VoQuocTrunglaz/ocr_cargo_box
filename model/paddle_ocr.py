import os
import cv2
import json
import re
import numpy as np
from paddleocr import PaddleOCR
from ultralytics import YOLO
from rapidfuzz import process, fuzz

# üîπ C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n
BASE_DIR = os.getcwd()
MODEL_DIR = os.path.join(BASE_DIR, "model", "runs", "detect")

def get_latest_model():
    train_folders = sorted(
        [f for f in os.listdir(MODEL_DIR) if f.startswith("train")],
        key=lambda f: os.path.getmtime(os.path.join(MODEL_DIR, f)),
        reverse=True
    )
    if not train_folders:
        raise FileNotFoundError("Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh YOLO!")

    model_path = os.path.join(MODEL_DIR, train_folders[0], "weights", "best.pt")
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y model t·∫°i: {model_path}")

    return model_path

MODEL_PATH = get_latest_model()

OUTPUT_DIR = os.path.join(BASE_DIR, "model", "output")
os.makedirs(OUTPUT_DIR, exist_ok=True)

# üîπ Load m√¥ h√¨nh YOLO v√† PaddleOCR
yolo_model = YOLO(MODEL_PATH)
ocr = PaddleOCR(
    lang="en",  
    det_db_box_thresh=0.4,  # Ng∆∞·ª°ng ph√°t hi·ªán ch·ªØ
    rec_algorithm="CRNN",  # S·ª≠ d·ª•ng thu·∫≠t to√°n nh·∫≠n di·ªán ch·ªØ t·ªët h∆°n
    use_angle_cls=True,
    det_db_unclip_ratio=1.8 # ƒêi·ªÅu ch·ªânh bi√™n ch·ªØ, tr√°nh m·∫•t k√Ω t·ª±
)

def detect_text(image_path):
    """Ph√°t hi·ªán v√πng ch·ª©a ch·ªØ b·∫±ng YOLO"""
    image = cv2.imread(image_path)
    if image is None:
        raise ValueError(f"‚ùå Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh {image_path}")

    results = yolo_model(image)[0]  # Ch·∫°y YOLO
    if results.boxes is None or len(results.boxes.xyxy) == 0:
        print("‚ö†Ô∏è Kh√¥ng ph√°t hi·ªán v√πng ch·ª©a ch·ªØ!")
        return image, []

    cropped_images = []
    for i, bbox in enumerate(results.boxes.xyxy):
        xmin, ymin, xmax, ymax = map(int, bbox.tolist())
        cropped = image[ymin:ymax, xmin:xmax]
        
        # L∆∞u v√πng c·∫Øt
        cropped_path = os.path.join(OUTPUT_DIR, f"cropped_{i}.jpg")
        cv2.imwrite(cropped_path, cropped)
        cropped_images.append((cropped_path, (xmin, ymin, xmax, ymax)))

    return image, cropped_images

def recognize_text(image_path):
    """Nh·∫≠n di·ªán vƒÉn b·∫£n t·ª´ ·∫£nh b·∫±ng PaddleOCR v·ªõi x·ª≠ l√Ω l·ªói"""
    results = ocr.ocr(image_path, cls=True)

    # Ki·ªÉm tra k·∫øt qu·∫£ tr·∫£ v·ªÅ c√≥ h·ª£p l·ªá kh√¥ng
    if not results or results[0] is None:
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y vƒÉn b·∫£n trong ·∫£nh!")
        return [] 

    recognized_texts = []
    for result in results[0]:
        if len(result) < 2: 
            continue
        bbox, (text, confidence) = result
        recognized_texts.append((text, confidence))
    
    return recognized_texts

def extract_container_number(detected_texts):
    """Tr√≠ch xu·∫•t s·ªë hi·ªáu container t·ª´ danh s√°ch detected_texts"""
    potential_prefix = None
    potential_serial = None
    potential_type = None

    container_regex = re.compile(r"^([A-Z]{4})(\d{6})$")  # T√°ch Prefix + Serial b·ªã d√≠nh li·ªÅn
    prefix_regex = re.compile(r"^[A-Z]{4}$")  # Prefix ri√™ng
    serial_regex = re.compile(r"^\d{6}$")  # Serial ri√™ng
    type_code_regex = re.compile(r"^[A-Z0-9]{3,4}$")  # Type Code h·ª£p l·ªá

    invalid_labels = {"MAX GROSS", "TARE", "NET", "CU.CAP."}

    for i, (text, confidence) in enumerate(detected_texts):
        text = text.strip().upper()

        if text in invalid_labels:
            continue

        # Ki·ªÉm tra Prefix + Serial b·ªã d√≠nh li·ªÅn (VD: "TTNU872638")
        match = container_regex.match(text)
        if match:
            potential_prefix, potential_serial = match.groups()
            continue

        # T√¨m Prefix ri√™ng (4 ch·ªØ c√°i)
        if prefix_regex.match(text):
            potential_prefix = text
            # Ki·ªÉm tra d√≤ng k·∫ø ti·∫øp c√≥ Serial kh√¥ng
            if i + 1 < len(detected_texts) and serial_regex.match(detected_texts[i + 1][0].strip().upper()):
                potential_serial = detected_texts[i + 1][0].strip().upper()
            continue

        # T√¨m Serial Number ri√™ng (6 s·ªë)
        if serial_regex.match(text):
            potential_serial = text
            # Ki·ªÉm tra d√≤ng tr∆∞·ªõc c√≥ Prefix kh√¥ng
            if i > 0 and prefix_regex.match(detected_texts[i - 1][0].strip().upper()):
                potential_prefix = detected_texts[i - 1][0].strip().upper()
            continue

        # X√°c ƒë·ªãnh Type Code (3-4 k√Ω t·ª± h·ª£p l·ªá)
        if type_code_regex.match(text):
            potential_type = text

        # N·∫øu ƒë√£ t√¨m ƒë·ªß Prefix + Serial + Type Code th√¨ tr·∫£ v·ªÅ k·∫øt qu·∫£
        if potential_prefix and potential_serial and potential_type:
            return {
                "prefix": potential_prefix,
                "serial_number": potential_serial,
                "type_code": potential_type
            }

    return None

def extract_numbers_from_text(detected_texts, index):
    """T√¨m ki·∫øm s·ªë li·ªáu li√™n quan t·ª´ danh s√°ch OCR"""
    numbers = []
    for i in range(index + 1, min(index + 4, len(detected_texts))):
        text, _ = detected_texts[i]
        text = text.replace("L8", "LB")
        text = text.replace("M3", "CU.M")
        text = text.replace(",", ".")
        found_numbers = re.findall(r"\d+\.\d+|\d+", text)
        numbers.extend([float(num) for num in found_numbers])  # Chuy·ªÉn sang float
    return numbers

def classify_fields(detected_texts):
    """Ph√¢n lo·∫°i th√¥ng tin container v√† g√°n c√°c gi√° tr·ªã t·ª´ OCR"""
    fields = {
        "container_number": {"prefix": None, "serial_number": None, "type_code": None},
        "container_info": {
            "Max Gross": {"kg": None, "lbs": None},
            "Tare Weight": {"kg": None, "lbs": None},
            "Max Payload": {"kg": None, "lbs": None},
            "Cube Volume": {"cu.m": None, "cu.ft": None}
        }
    }

    label_map = {
    "Max Gross": ["GROSSWE", "GROSSWT", "MAX GROSS", "MAX.GROSS", "MAX.WT"],
    "Tare Weight": ["TARE"],
    "Max Payload": ["PAYLOAD", "MAX.CARGO", "NET"],
    "Cube Volume": ["CUBE", "CU.CAP", "CU CAP"]
    }

    MIN_CONFIDENCE = 0.8

    # ∆Øu ti√™n ph√°t hi·ªán s·ªë hi·ªáu container tr∆∞·ªõc
    container_number = extract_container_number(detected_texts)
    if container_number:
        fields["container_number"].update(container_number)
        print(f"Container number detected: {container_number}")

    valid_texts = []  # Danh s√°ch c√°c vƒÉn b·∫£n h·ª£p l·ªá
    for text, confidence in detected_texts:
        text = text.upper().strip()
        if confidence < MIN_CONFIDENCE:
            continue  # B·ªè qua vƒÉn b·∫£n c√≥ ƒë·ªô ch√≠nh x√°c th·∫•p

        # Ki·ªÉm tra n·∫øu l√† nh·ªØng vƒÉn b·∫£n kh√¥ng h·ª£p l·ªá
        if re.match(r"^[A-Z]{3,4}$", text) and confidence < 0.6:
            continue  # Lo·∫°i b·ªè nh·ªØng t·ª´ n·∫øu ƒë·ªô ch√≠nh x√°c th·∫•p

        valid_texts.append((text, confidence))

    # Ti·∫øp t·ª•c x·ª≠ l√Ω th√¥ng tin tr·ªçng l∆∞·ª£ng v√† th·ªÉ t√≠ch
    for i, (text, confidence) in enumerate(valid_texts):
        text = text.upper().strip()
        # B·ªè qua n·∫øu l√† s·ªë hi·ªáu container
        if container_number and text in container_number.values():
            continue

        current_label = None
        for label, field_name in label_map.items():
            best_match = process.extractOne(text, field_name, scorer=fuzz.ratio)

            if best_match and best_match[1] > 70:
                current_label = label
                print(f"Label found: '{text}' -> {label} (Match: {best_match[0]})")
                break

        if current_label:
            numbers = extract_numbers_from_text(valid_texts, i)
            print(f"Numbers extracted for {current_label}: {numbers}")

            # Ki·ªÉm tra xem c√≥ m·ªôt ho·∫∑c hai s·ªë kh√¥ng
            if len(numbers) > 0:
                if current_label == "Cube Volume":
                    fields["container_info"][current_label]["cu.m"] = numbers[0]
                    if len(numbers) > 1:
                        fields["container_info"][current_label]["cu.ft"] = numbers[1]
                else:
                    fields["container_info"][current_label]["kg"] = numbers[0]
                    if len(numbers) > 1:
                        fields["container_info"][current_label]["lbs"] = numbers[1]
            
    return json.dumps(fields, indent=4, ensure_ascii=False)

def process_ocr(image_path):
    """Chu·ªói x·ª≠ l√Ω ƒë·∫ßy ƒë·ªß: ph√°t hi·ªán ch·ªØ, c·∫Øt ·∫£nh, nh·∫≠n di·ªán vƒÉn b·∫£n"""
    image, cropped_images = detect_text(image_path)

    if not cropped_images:
        print("‚ö†Ô∏è Kh√¥ng c√≥ ch·ªØ ƒë·ªÉ nh·∫≠n di·ªán!")
        return

    detected_texts = []
    for cropped_img, bbox in cropped_images:
        texts = recognize_text(cropped_img)
        for text, confidence in texts:
            detected_texts.append((text, confidence, bbox))
            print(f"üìå VƒÉn b·∫£n: {text} | üéØ ƒê·ªô ch√≠nh x√°c: {confidence:.2f}")

    # V·∫Ω k·∫øt qu·∫£ l√™n ·∫£nh g·ªëc
    #visualize_results(image, detected_texts)

    json_output = classify_fields([(text, confidence) for text, confidence, _ in detected_texts])
    print("üì¶ JSON K·∫øt qu·∫£:\n", json_output)


# üîπ Ch·∫°y th·ª≠ nghi·ªám
image_path = os.path.join(BASE_DIR, "data", "test", "images", "IMG_20210906-15132785_jpg.rf.6602e1e07202f7f034b52c969b47ea5e.jpg")
process_ocr(image_path)
