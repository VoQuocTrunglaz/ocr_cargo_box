import os
import cv2
import re
import json
import numpy as np
from paddleocr import PaddleOCR
from ultralytics import YOLO
import google.generativeai as genai
from pathlib import Path

# üîπ C·∫•u h√¨nh API Gemini
API_KEY = "AIzaSyAlL5ivuNQnSQxc7UwKxsSrgRygFsetqLo"
genai.configure(api_key=API_KEY)

BASE_DIR = Path(__file__).resolve().parents[1]  

# X√°c ƒë·ªãnh ƒë∆∞·ªùng d·∫´n ƒë·∫øn model, ·∫£nh test v√† th∆∞ m·ª•c k·∫øt qu·∫£
MODEL_PATH = Path(__file__).resolve().parent / "runs" / "detect" / "train" / "weights" / "best.pt"

# üîπ Load m√¥ h√¨nh YOLO v√† PaddleOCR
yolo_model = YOLO(MODEL_PATH)  
ocr = PaddleOCR(lang="en", use_angle_cls=True, rec_algorithm="CRNN")

# Th∆∞ m·ª•c l∆∞u v√πng ·∫£nh c·∫Øt
OUTPUT_DIR = "cropped_text_regions"
os.makedirs(OUTPUT_DIR, exist_ok=True)

def detect_text(image_path):
    """Ph√°t hi·ªán v√πng ch·ª©a ch·ªØ b·∫±ng YOLO"""
    image = cv2.imread(image_path)
    if image is None:
        raise ValueError(f"‚ùå Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh {image_path}")

    results = yolo_model(image)[0]  # Ch·∫°y YOLO
    if results.boxes is None or len(results.boxes.xyxy) == 0:
        print("‚ö†Ô∏è Kh√¥ng ph√°t hi·ªán v√πng ch·ª©a ch·ªØ!")
        return image, []

    cropped_images = []
    for i, bbox in enumerate(results.boxes.xyxy):
        xmin, ymin, xmax, ymax = map(int, bbox.tolist())
        cropped = image[ymin:ymax, xmin:xmax]
        
        # L∆∞u v√πng c·∫Øt
        cropped_path = os.path.join(OUTPUT_DIR, f"cropped_{i}.jpg")
        cv2.imwrite(cropped_path, cropped)
        cropped_images.append((cropped_path, (xmin, ymin, xmax, ymax)))

    return image, cropped_images

def recognize_text(image_path):
    """Nh·∫≠n di·ªán vƒÉn b·∫£n t·ª´ ·∫£nh b·∫±ng PaddleOCR v·ªõi x·ª≠ l√Ω l·ªói"""
    results = ocr.ocr(image_path, cls=True)

    # Ki·ªÉm tra k·∫øt qu·∫£ tr·∫£ v·ªÅ c√≥ h·ª£p l·ªá kh√¥ng
    if not results or results[0] is None:
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y vƒÉn b·∫£n trong ·∫£nh!")
        return [] 

    recognized_texts = []
    for result in results[0]:
        if len(result) < 2: 
            continue
        bbox, (text, confidence) = result
        recognized_texts.append((text, confidence))
    
    return recognized_texts

def classify_with_gemini(texts):
    """Ph√¢n lo·∫°i danh s√°ch vƒÉn b·∫£n v√†o JSON v·ªõi ƒë·ªãnh d·∫°ng chi ti·∫øt."""
    prompt = (
        "H√£y ki·ªÉm tra danh s√°ch d·ªØ li·ªáu sau, s·ª≠a c√°c ƒë∆°n v·ªã ƒëo b·ªã sai (n·∫øu c√≥)"
        "H√£y ph√¢n lo·∫°i danh s√°ch sau th√†nh JSON theo format d∆∞·ªõi ƒë√¢y. "
        "Ch·ªâ tr·∫£ v·ªÅ JSON h·ª£p l·ªá, kh√¥ng c√≥ m√¥ t·∫£, kh√¥ng c√≥ text d∆∞ th·ª´a.\n\n"
        "FORMAT JSON Y√äU C·∫¶U:\n"
        "```json\n"
        "{\n"
        '  "container_number": {\n'
        '    "prefix": "",\n'
        '    "serial": "",\n'
        '    "type_code": ""\n'
        "  },\n"
        '  "container_info": {\n'
        '    "max_gross": {"":"kg": "", "lbs": "" },\n'
        '    "tare_weight": { "kg": "", "lbs": "" },\n'
        '    "max_payload": { "kg": "", "lbs": "" },\n'
        '    "cube_volume": { "m3": "", "cuft": "" }\n'
        "  }\n"
        "}\n"
        "```\n\n"
        "C√ÅCH PH√ÇN LO·∫†I:\n"
        "- `container_number` g·ªìm:\n"
        "  - `prefix`: 4 ch·ªØ c√°i ƒë·∫ßu c·ªßa s·ªë container.\n"
        "  - `serial`: 6 ch·ªØ s·ªë cu·ªëi c·ªßa s·ªë container.\n"
        "  - `type_code`: M√£ lo·∫°i container.\n"
        "- `container_info` g·ªìm:\n"
        "  - `max_gross`: Gi√° tr·ªã c·ªßa MAX.GROSS (c·∫£ kg v√† lbs).\n"
        "  - `tare_weight`: Gi√° tr·ªã c·ªßa TARE (c·∫£ kg v√† lbs).\n"
        "  - `max_payload`: Gi√° tr·ªã c·ªßa MAX.PAYLOAD (c·∫£ kg v√† lbs).\n"
        "  - `cube_volume`: Gi√° tr·ªã c·ªßa CUBE (c·∫£ m¬≥ v√† cuft).\n\n"
        f"üîπ D·ªØ li·ªáu ƒë·∫ßu v√†o: {texts}\n"
        "üîπ Ch·ªâ tr·∫£ v·ªÅ JSON h·ª£p l·ªá!"
    )
    try:
        model = genai.GenerativeModel("gemini-2.0-flash")
        response = model.generate_content(prompt)

        if not response or not response.text:
            print("‚ö†Ô∏è Kh√¥ng nh·∫≠n ƒë∆∞·ª£c ph·∫£n h·ªìi t·ª´ Gemini")
            return None

        # üõ†Ô∏è **Tr√≠ch xu·∫•t JSON t·ª´ ph·∫£n h·ªìi**
        json_match = re.search(r'\{.*\}', response.text, re.DOTALL)
        if not json_match:
            print("‚ùå L·ªói: Gemini kh√¥ng tr·∫£ v·ªÅ JSON h·ª£p l·ªá!")
            return None

        json_result = json.loads(json_match.group(0))  # Chuy·ªÉn ƒë·ªïi th√†nh dict
        return json_result

    except json.JSONDecodeError:
        print("‚ùå L·ªói khi parse JSON t·ª´ Gemini!")
        return None
    except Exception as e:
        print("‚ùå L·ªói khi g·ªçi API Gemini:", str(e))
        return None

def process_ocr_with_gemini(image_path):
    """Chu·ªói x·ª≠ l√Ω ƒë·∫ßy ƒë·ªß: ph√°t hi·ªán ch·ªØ, c·∫Øt ·∫£nh, nh·∫≠n di·ªán vƒÉn b·∫£n, ph√¢n lo·∫°i b·∫±ng Gemini"""
    image, cropped_images = detect_text(image_path)
    if not cropped_images:
        return
    
    detected_texts = []
    for cropped_path, _ in cropped_images:
        texts = recognize_text(cropped_path)
        detected_texts.extend([text for text, _ in texts])
    
    if not detected_texts:
        print("‚ö†Ô∏è Kh√¥ng c√≥ vƒÉn b·∫£n ƒë·ªÉ ph√¢n lo·∫°i!")
        return
    
    # G·ªçi API Gemini ƒë·ªÉ ph√¢n lo·∫°i
    classification_result = classify_with_gemini(detected_texts)
    print("üì¶ K·∫øt qu·∫£ ph√¢n lo·∫°i t·ª´ Gemini:\n", classification_result)

# üîπ Ch·∫°y th·ª≠ nghi·ªám
image_path = BASE_DIR / "data" / "test" / "images" / "4_jpg.rf.43e07ad086c9d9c9b06005367b48bf41.jpg" # C·∫≠p nh·∫≠t ƒë∆∞·ªùng d·∫´n ·∫£nh
process_ocr_with_gemini(image_path)
